{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Clustering and the curse of dimensionality\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ariel Rossanigo**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quien soy?\n",
    "\n",
    "* Ariel Rossanigo\n",
    "* Artificial Intelligence teacher at UCSE-DAR\n",
    "* Developer, Data Scientist\n",
    "* Co-Founder of Bloom AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clustering \n",
    "\n",
    "<div><img src=\"./imgs/clustering.jpg\" width=\"50%\" style=\"float: right; margin: 10px;\" align=\"middle\"></div>\n",
    "\n",
    "\n",
    "#### *Encontrar grupos de datos que son similares*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* La definicion parece simple... pero hay que ver que consideramos grupos y que consideramos similares \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from under_the_carpet import *\n",
    "\n",
    "data = np.load('clusterable_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%time kmeans = cluster.KMeans(n_clusters=6).fit(data)\n",
    "plot_data(data, kmeans.predict(data), legend=False, title='K-Means', centroids=kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Como funciona\n",
    "* Ventajas: Converge rapido\n",
    "* Desventajas: Hay que elegir K; cluster esféricos; todas las instancias pertenecen a un cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%time affinity = cluster.AffinityPropagation(damping=0.985, max_iter=200).fit(data)\n",
    "plot_data(data, affinity.labels_, title='Affinity propagation', legend=False, centroids=affinity.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Como funciona\n",
    "* Ventajas: No hay que elegir K\n",
    "* Desventajas: Hay que elegir damping; cluster esféricos; todas las instancias pertenecen a un cluster; Lento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%time ms = cluster.MeanShift(bandwidth=0.2, cluster_all=False).fit(data)\n",
    "plot_data(data, ms.labels_, title='Mean Shift', legend=False, centroids=ms.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Como funciona\n",
    "* Ventajas: No hay que elegir K, No todas las instancias pertenecen a un cluster \n",
    "* Desventajas: Hay que elegir otros parametros; cluster esféricos; Lento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%time agg = cluster.AgglomerativeClustering(n_clusters=None, distance_threshold=2).fit(data)\n",
    "plot_data(data, agg.labels_, title='Agglomerative clustering', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Como funciona\n",
    "* Ventajas: Algunas formas de elegir que cluster fusionar no restringen la forma de los clusters\n",
    "* Desventajas: Hay que elegir donde cortar, es el equivalente a elegir el K; si los datasets son grandes, la cantidad de informacion es abrumadora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%time dbscan = cluster.DBSCAN(eps=0.02, min_samples=5).fit(data)\n",
    "plot_data(data, dbscan.labels_, title='DBSCAN clustering', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div><img src=\"./imgs/dbscan.png\" width=\"40%\" style=\"float: left; margin: 10px;\" align=\"middle\"></div>\n",
    "\n",
    "\n",
    "<div><img src=\"./imgs/dbscan_working.gif\" width=\"50%\" style=\"float: right; margin: 10px;\" align=\"middle\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Como funciona\n",
    " * Tiene core points, border points y outliers\n",
    " * Dos parametros importantes: epsilon y min_samples\n",
    "* Ventajas: Encuentra areas densas y elimina outliers\n",
    "* Desventajas: Elegir los parametros es dificil si hay mas de 2 dimensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clustering \n",
    "\n",
    "* El algoritmo de clustering depende mucho de que necesitamos\n",
    "* En muchas aplicaciones, es encontrar regiones densas de casos en medio de ruido\n",
    "* La opción por defecto quizas debiera ser basada en densidad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Curse of dimensionality\n",
    "\n",
    "<div><img src=\"./imgs/sphere.png\" width=\"40%\" style=\"float: left; margin: 10px;\" align=\"middle\"></div>\n",
    "\n",
    "\n",
    "<div><img src=\"./imgs/curse_in_distance.png\" width=\"50%\" style=\"float: right; margin: 10px;\" align=\"middle\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* El volumen del espacio se incremente, los datos quedan dispersos. Baja significancia estadistica. Ej de promedio con un solo campo categorico y luego con dos.\n",
    "* Particularmente en clustering, hace que las distancias entre puntos tiendan a ser todas similares\n",
    "* Otro no menor, se complica \"mirar\" los datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reducción de dimensionalidad\n",
    "\n",
    "*Find the latent features in your data*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Por que?\n",
    " * Quiero visualizar mis datos\n",
    " * Reducir redundancia\n",
    " \n",
    "* Hay dos formas de reducir la dimensionalidad:\n",
    " * Feature selection\n",
    " * Feature projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "digits_X, digits_y = load_mnist(30_000)\n",
    "\n",
    "for index, (image, label) in enumerate(zip(digits_X[:32], digits_y[:32])):\n",
    "    plt.subplot(4, 8, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.reshape(28, 28), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PCA\n",
    "\n",
    "<div><img src=\"./imgs/pca.png\" width=\"80%\" style=\"float: left; margin: 10px;\" align=\"middle\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Es rapido\n",
    "* Puede capturar solo correlaciones lineales entre variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time emb = PCA(n_components=2).fit_transform(digits_X)\n",
    "plot_data(emb, labels=digits_y, title='PCA a dos dimensiones')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### UMAP\n",
    "\n",
    "<div><img src=\"./imgs/umap.png\" width=\"100%\" style=\"float: left; margin: 10px;\" align=\"middle\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Consiste de dos etapas: encontrar un grafo y luego optimizar una representacion en menos dimensiones\n",
    "* Tiene algunas ventajas:\n",
    " * Mantiene las relaciones globales\n",
    " * Sirve para hacer visualizaciones (trata de separar los clusters)\n",
    " * se puede usar como paso previo a un algoritmo de clusting (se puede facilmente generar varias dimensiones)\n",
    " * Se puede hacer reduccion de dimensionalidad supervisada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%time emb = UMAP().fit_transform(digits_X)\n",
    "plot_data(emb, labels=digits_y, title='UMAP a dos dimensiones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%time emb = UMAP().fit_transform(digits_X, y=digits_y)\n",
    "plot_data(emb, labels=digits_y, title='UMAP supervisado a dos dimensiones')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Realidad ¿?\n",
    "\n",
    "<div><img src=\"./imgs/dd.jpg\" width=\"60%\" style=\"float: right; margin: 10px;\"  align=\"middle\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* El ejemplo (creado de forma ficticia) consta de personajes que se usaron para jugar D&D.\n",
    "* Cada personaje esta caracterizado por su raza, altura, peso, edad, y los puntos extra que tiene en algunas habilidades(fortaleza, carisma y constitucion)\n",
    "* El dataset fue creado siguiendo algunas estadisticas que encontre por internet, por ejemplo:\n",
    " * la distribución de las razas que se utilizan para jugar es real\n",
    " * los enanos miden entre 4'2'' y 4'8'', pesan... etc.\n",
    " * la idea seria ver si los algoritmos que vimos son capaces de detectar los grupos generados por las distintas clases (9 en total)\n",
    " \n",
    "* Tenemos una columna most_common_race que tiene un 1 para las 3 razas mas comunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "characters = load_dd(30_000)\n",
    "characters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "characters.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dfm = DataFrameMapper([\n",
    "    (['height'], StandardScaler()),\n",
    "    (['weight'], StandardScaler()),\n",
    "    (['age'], StandardScaler()),\n",
    "    (['strength'], None),\n",
    "    (['charisma'], None),\n",
    "    (['constitution'], None),\n",
    "])\n",
    "\n",
    "X = dfm.fit_transform(characters)\n",
    "y = characters.race\n",
    "%time emb = UMAP(random_state=42).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Lo primero que vamos a ver es si podemos visualizar los datos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_data(emb, y, title='UMAP with informative features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "noise_columns = []\n",
    "for i in range(100):\n",
    "    col = f'noisy_{i}'\n",
    "    characters[col] = np.random.random(size=len(characters))\n",
    "    noise_columns.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Ahora vamos a tentar a la suerte, dijimos que si hay muchas dimensiones con ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dfm = DataFrameMapper([\n",
    "    (['height'], StandardScaler()),\n",
    "    (['weight'], StandardScaler()),\n",
    "    (['age'], StandardScaler()),\n",
    "    (['strength'], None),\n",
    "    (['charisma'], None),\n",
    "    (['constitution'], None),\n",
    "    (noise_columns, StandardScaler())\n",
    "])\n",
    "\n",
    "X = dfm.fit_transform(characters)\n",
    "y = characters.race\n",
    "\n",
    "%time embed = UMAP(random_state=42).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_data(embed, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Agregando muchas columnas con ruido ya no se distingue los clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y2 = characters.most_common_race\n",
    "\n",
    "%time embed = UMAP(random_state=42).fit_transform(X, y=y2)\n",
    "plot_data(embed, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Incluso en modo supervisado no es capaz de generar los clusters que teniamos al inicio\n",
    "* Debieramos eliminar el ruido, quizas eliminando dimensiones. Vamos a intentar hacerlo usando Arboles de decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Forest embeddings\n",
    "\n",
    "*Usar las hojas de los arboles como embedding de los datos*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* La idea es entrenar un ensemble de arboles, usando como target el campo de razas comunes.\n",
    "* Luego a cada ejemplo lo pasamos por el ensemble y nos quedamos con el id de hoja de cada uno de los arboles\n",
    "* Lo esperable es que ejemplos parecidos vayan \"cayendo\" en las mismas hojas de los arboles.\n",
    "* Si hay dos subgrupos diferentes para un valor del target, podriamos suponer que pasarian por distintos caminos en cada arbol.\n",
    "\n",
    "* Luego aplicariamos la reduccion de dimensionalidad sobre el listado de hojas en lugar de usar las features originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=100, min_samples_leaf=3000, max_features=0.8, \n",
    "                          bootstrap=True, class_weight='balanced', max_leaf_nodes=10)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "preds = cross_val_predict(et, X, y2, cv=skf, method='predict_proba')\n",
    "\n",
    "print('Area under the ROC Curve:', metrics.roc_auc_score(y2, preds[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Medimos que el ensemble no este sobre-entrenando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "et.fit(X, y=y2)\n",
    "leaves = et.apply(X)\n",
    "leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Entrenamos el arbol con todos los datos\n",
    "* Vemos que para cada ejemplo tenemos el array de indices que indica en que hoja cayo ese ejemplo para cada arbol del ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%time umap_reducer = UMAP(metric='hamming').fit(leaves)\n",
    "final_emb = umap_reducer.transform(leaves)\n",
    "plot_data(final_emb, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Usamos Hamming distance porque nos interesa comparar en cuantas hojas coinciden los ejemplos.\n",
    "\n",
    "Como se puede ver, logramos que vuelvan a aparecer los clusters en el grafico.\n",
    "Ahora podriamos probar alguna técnica de clustering y plotear los resultados usando este ultimo embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%time dbscan = cluster.DBSCAN().fit(X)\n",
    "plot_data(final_emb, dbscan.labels_, title='DBSCAN clustering', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Se puede ver que DBSCAN no es capaz de encontrar clusters, tiene sentido porque por la alta dimensionalidad los puntos tienden a estar todos dispersos, vamos a intentar repetir el truco del arbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%time dbscan = cluster.DBSCAN(eps=1).fit(final_emb)\n",
    "plot_data(final_emb, dbscan.labels_, title='DBSCAN clustering', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Podemos ver que usando solo el embedding en 2D, dbscan funciona bien.\n",
    "Que pasa ahora si tenemos nuevos ejemplos que clusterizar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "more_characters = load_dd(80_000)\n",
    "noise_columns = []\n",
    "for i in range(100):\n",
    "    col = f'noisy_{i}'\n",
    "    more_characters[col] = np.random.random(size=len(more_characters))\n",
    "    noise_columns.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_new = dfm.fit_transform(more_characters)\n",
    "y_new = more_characters.race\n",
    "\n",
    "%time new_leaves = et.apply(X_new)\n",
    "%time new_emb = umap_reducer.transform(new_leaves)\n",
    "%time final_dbscan = cluster.DBSCAN(eps=1).fit(new_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_data(new_emb, final_dbscan.labels_, title='DBSCAN clustering', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Podemos ver que todo el pipeline anda bastante rapido y bien\n",
    "* En esta ultima parte del pipeline nunca usamos most_common_races, ergo, podemos clusterizar de forma semi supervisada, o hacer metric learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusiones\n",
    "\n",
    "* Clusterizar no es una tarea sencilla\n",
    "* DBSCAN es una buena opción para empezar (o HDBSCAN)\n",
    "* Si tenemos muchas dimensiones tenemos que tratar de reducirlas primero\n",
    "* Un buen pipeline puede ser combinando varias técnicas\n",
    " * Rule of thumb: **(300+) => PCA => (50) => UMAP (10-20) => DBSCAN / Classification**\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Gracias! Preguntas?\n",
    "\n",
    "\n",
    "<div style=\"float: left;\"><img src=\"../common/imgs/man-qmark.jpg\" width=\"300\" align=\"middle\"></div> \n",
    "\n",
    "<div>\n",
    "<div>\n",
    "  <img src=\"../common/imgs/gmail-1162901_960_720.png\" style=\"width: 30px; float: left; vertical-align:middle; margin: 0px;\">\n",
    "  <span style=\"line-height:30px; vertical-align:middle; margin-left: 10px;\">arielrossanigo@gmail.com</span>\n",
    "</div>\n",
    "<div>\n",
    "  <img src=\"../common/imgs/twitter-312464_960_720.png\" style=\"width: 30px; float: left; vertical-align:middle; margin: 0px;\">\n",
    "  <span style=\"line-height:30px; vertical-align:middle; margin-left: 10px;\">@arielrossanigo</span>\n",
    "</div>\n",
    "<div>\n",
    "  <img src=\"../common/imgs/github-154769__340.png\" style=\"width: 30px; float: left; vertical-align:middle; margin: 0px;\">\n",
    "  <span style=\"line-height:30px; vertical-align:middle; margin-left: 10px;\">https://github.com/arielrossanigo</span>\n",
    "</div>\n",
    "<div>\n",
    "  <img src=\"../common/imgs/Linkedin_icon.svg\" style=\"width: 30px; float: left; vertical-align:middle; margin: 0px;\">\n",
    "  <span style=\"line-height:30px; vertical-align:middle; margin-left: 10px;\">https://www.linkedin.com/in/arielrossanigo/</span>\n",
    "</div>\n",
    "\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
